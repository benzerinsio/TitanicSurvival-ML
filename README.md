# ğŸš¢ PrevisÃ£o de SobrevivÃªncia no Titanic
*Projeto de Machine Learning - Felipe V. Sousa*

Bem-vindo(a)! Este repositÃ³rio apresenta uma anÃ¡lise completa da competiÃ§Ã£o Titanic do Kaggle, combinando prÃ©-processamento avanÃ§ado, feature engineering e modelagem de Machine Learning para prever a sobrevivÃªncia dos passageiros com alta precisÃ£o.

ğŸ”— [Visualizar o Notebook](https://github.com/benzerinsio/TitanicSurvival-ML/blob/main/ML_Titanic.ipynb)

## ğŸ¯ Objetivo da AnÃ¡lise

Analisar o dataset Titanic para prever a sobrevivÃªncia dos passageiros, utilizando tÃ©cnicas de prÃ©-processamento detalhado, feature engineering baseado em tÃ­tulos e avaliaÃ§Ã£o de mÃºltiplos modelos de Machine Learning. O foco Ã© identificar fatores-chave (ex.: classe, sexo, idade) e alcanÃ§ar um desempenho competitivo na submissÃ£o ao Kaggle.

## ğŸ“Š Fonte de Dados

Dados da competiÃ§Ã£o Titanic (Kaggle), com 891 registros de treino (12 colunas, incluindo `Survived`) e 418 registros de teste para previsÃ£o.

## ğŸ› ï¸ Bibliotecas Utilizadas

- **Pandas**: ManipulaÃ§Ã£o e prÃ©-processamento de dados.  
- **Scikit-learn**: Modelos de ML, GridSearchCV e mÃ©tricas de avaliaÃ§Ã£o.  
- **Seaborn**: VisualizaÃ§Ãµes estatÃ­sticas (ex.: matriz de correlaÃ§Ã£o).  
- **Matplotlib**: GrÃ¡ficos complementares.  
- **StandardScaler**: NormalizaÃ§Ã£o para modelos sensÃ­veis Ã  escala.

## ğŸ’¬ ConclusÃ£o

Este projeto implementa uma pipeline robusta: limpeza de dados (remoÃ§Ã£o de `Cabin`, `Ticket`, tratamento de `Age`), feature engineering (tÃ­tulos extraÃ­dos de `Name`) e avaliaÃ§Ã£o de modelos (RegressÃ£o LogÃ­stica, Random Forest, Decision Tree, SVM). O SVM (`C=1`, `gamma=0.1`, `kernel='rbf'`) destacou-se com o melhor desempenho combinado em validaÃ§Ã£o cruzada e conjunto de validaÃ§Ã£o, gerando uma submissÃ£o competitiva. O notebook, otimizado para visualizaÃ§Ã£o via nbviewer, oferece uma base sÃ³lida para futuros ajustes, como ensembles avanÃ§ados ou feature engineering adicional.